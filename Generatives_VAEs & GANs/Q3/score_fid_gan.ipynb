{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "Using downloaded and verified file: svhn/test_32x32.mat\n",
      "FID score: 285932.7552095551\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import classify_svhn\n",
    "from classify_svhn import Classifier\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "import scipy\n",
    "\n",
    "SVHN_PATH = \"svhn\"\n",
    "PROCESS_BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def get_sample_loader(path, batch_size):\n",
    "    \"\"\"\n",
    "    Loads data from `[path]/samples`\n",
    "\n",
    "    - Ensure that path contains only one directory\n",
    "      (This is due ot how the ImageFolder dataset loader\n",
    "       works)\n",
    "    - Ensure that ALL of your images are 32 x 32.\n",
    "      The transform in this function will rescale it to\n",
    "      32 x 32 if this is not the case.\n",
    "\n",
    "    Returns an iterator over the tensors of the images\n",
    "    of dimension (batch_size, 3, 32, 32)\n",
    "    \"\"\"\n",
    "    data = torchvision.datasets.ImageFolder(\n",
    "        path,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize((32, 32), interpolation=2),\n",
    "            classify_svhn.image_transform\n",
    "        ])\n",
    "    )\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        data,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "def get_test_loader(batch_size):\n",
    "    \"\"\"\n",
    "    Downloads (if it doesn't already exist) SVHN test into\n",
    "    [pwd]/svhn.\n",
    "\n",
    "    Returns an iterator over the tensors of the images\n",
    "    of dimension (batch_size, 3, 32, 32)\n",
    "    \"\"\"\n",
    "    testset = torchvision.datasets.SVHN(\n",
    "        SVHN_PATH, split='test',\n",
    "        download=True,\n",
    "        transform=classify_svhn.image_transform\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return testloader\n",
    "\n",
    "\n",
    "def extract_features(classifier, data_loader):\n",
    "    \"\"\"\n",
    "    Iterator of features for each image.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for x, _ in data_loader:\n",
    "            h = classifier.extract_features(x).numpy()\n",
    "            for i in range(h.shape[0]):\n",
    "                yield h[i]\n",
    "\n",
    "#%%\n",
    "def calculate_fid_score(sample_feature_iterator,\n",
    "                        testset_feature_iterator):\n",
    "    \"\"\"\n",
    "        To be implemented by you!\n",
    "        Code adapted from https://github.com/bioinf-jku/TTUR   \n",
    "        https://github.com/bioinf-jku?utf8=%E2%9C%93&q=&type=&language=\n",
    "        \n",
    "        to use PyTorch instead\n",
    "        of Tensorflow\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "        Calculates the Frechet Inception Distance (FID) to evalulate GANs\n",
    "        The FID metric calculates the distance between two distributions of images.\n",
    "        Typically, we have summary statistics (mean & covariance matrix) of one\n",
    "        of these distributions, while the 2nd distribution is given by a GAN.\n",
    "        When run as a stand-alone program, it compares the distribution of\n",
    "        images that are stored as PNG/JPEG at a specified location with a\n",
    "        distribution given by summary statistics (in pickle format).\n",
    "        The FID is calculated by assuming that X_1 and X_2 are the activations of\n",
    "        the pool_3 layer of the inception net for generated samples and real world\n",
    "        samples respectively.\n",
    "    \"\"\"\n",
    "    \n",
    "    #raise NotImplementedError(\n",
    "    #    \"TO BE IMPLEMENTED.\"\n",
    "    #    \"Part of Assignment 3 Quantitative Evaluations\"\n",
    "    #)\n",
    "    x = np.asarray(list(islice(sample_feature_iterator, 1000)))\n",
    "    y = np.asarray(list(islice(testset_feature_iterator, 1000)))\n",
    "    mu_x = np.mean(x, axis=0)\n",
    "    mu_y = np.mean(y, axis=0)\n",
    "    sigma_x = np.cov(x, rowvar=False)\n",
    "    sigma_y = np.cov(y, rowvar=False)\n",
    "    MSE = np.dot((mu_x - mu_y),(mu_x - mu_y).T)\n",
    "    sigma = sigma_x + sigma_y - 2 * scipy.linalg.sqrtm(sigma_x * sigma_y)\n",
    "    FID = MSE + np.trace(sigma)\n",
    "    return FID\n",
    "\n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description='Score a directory of images with the FID score.')\n",
    "#     parser.add_argument('--model', type=str, default=\"svhn_classifier.pt\",\n",
    "#                         help='Path to feature extraction model.')\n",
    "#     parser.add_argument('directory', type=str,\n",
    "#                         help='Path to image directory')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "\n",
    "#     quit = False\n",
    "#     if not os.path.isfile(args.model):\n",
    "#         print(\"Model file \" + args.model + \" does not exist.\")\n",
    "#         quit = True\n",
    "#     if not os.path.isdir(args.directory):\n",
    "#         print(\"Directory \" + args.directory + \" does not exist.\")\n",
    "#         quit = True\n",
    "#     if quit:\n",
    "#         exit()\n",
    "    model = 'svhn_classifier.pt'\n",
    "    directory = 'images/gan'\n",
    "    print(\"Test\")\n",
    "    classifier = torch.load(model, map_location='cpu')\n",
    "    classifier.eval()\n",
    "\n",
    "    sample_loader = get_sample_loader(directory,\n",
    "                                      PROCESS_BATCH_SIZE)\n",
    "    sample_f = extract_features(classifier, sample_loader)\n",
    "\n",
    "    test_loader = get_test_loader(PROCESS_BATCH_SIZE)\n",
    "    test_f = extract_features(classifier, test_loader)\n",
    "\n",
    "    fid_score = calculate_fid_score(sample_f, test_f)\n",
    "    print(\"FID score:\", fid_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
