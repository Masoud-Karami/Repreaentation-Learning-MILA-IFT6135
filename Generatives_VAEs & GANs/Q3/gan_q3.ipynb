{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Using downloaded and verified file: svhn/train_32x32.mat\n",
      "Using downloaded and verified file: svhn/test_32x32.mat\n",
      "------- EPOCH 0 --------\n",
      "Training example 0 / 1031. DiscLoss: 1.12, GenLoss: 0.20\n",
      "Training example 100 / 1031. DiscLoss: -818.19, GenLoss: 134.29\n",
      "Training example 200 / 1031. DiscLoss: -1759.81, GenLoss: 176.79\n",
      "Training example 300 / 1031. DiscLoss: -4667.76, GenLoss: 528.02\n",
      "Training example 400 / 1031. DiscLoss: -6183.53, GenLoss: 691.95\n",
      "Training example 500 / 1031. DiscLoss: -10119.76, GenLoss: 1078.84\n",
      "Training example 600 / 1031. DiscLoss: -21184.94, GenLoss: 1855.12\n",
      "Training example 700 / 1031. DiscLoss: -27660.90, GenLoss: 2722.81\n",
      "Training example 800 / 1031. DiscLoss: -36460.72, GenLoss: 3461.18\n",
      "Training example 900 / 1031. DiscLoss: -47889.07, GenLoss: 4476.22\n",
      "Training example 1000 / 1031. DiscLoss: -55621.55, GenLoss: 5453.67\n",
      "------- EPOCH 1 --------\n",
      "Training example 0 / 1031. DiscLoss: -641.73, GenLoss: 303.13\n",
      "Training example 100 / 1031. DiscLoss: -69902.33, GenLoss: 6670.32\n",
      "Training example 200 / 1031. DiscLoss: -80725.51, GenLoss: 7774.70\n",
      "Training example 300 / 1031. DiscLoss: -82258.34, GenLoss: 8689.12\n",
      "Training example 400 / 1031. DiscLoss: -101691.80, GenLoss: 9856.58\n",
      "Training example 500 / 1031. DiscLoss: -113656.19, GenLoss: 11070.73\n",
      "Training example 600 / 1031. DiscLoss: -116497.18, GenLoss: 12245.83\n",
      "Training example 700 / 1031. DiscLoss: -79150.60, GenLoss: 12300.66\n",
      "Training example 800 / 1031. DiscLoss: -142816.66, GenLoss: 13961.99\n",
      "Training example 900 / 1031. DiscLoss: -156002.08, GenLoss: 15271.16\n",
      "Training example 1000 / 1031. DiscLoss: -169627.03, GenLoss: 16626.20\n",
      "------- EPOCH 2 --------\n",
      "Training example 0 / 1031. DiscLoss: -1803.52, GenLoss: 886.46\n",
      "Training example 100 / 1031. DiscLoss: -187404.03, GenLoss: 18466.40\n",
      "Training example 200 / 1031. DiscLoss: 27506.30, GenLoss: 17547.87\n",
      "Training example 300 / 1031. DiscLoss: 1805.55, GenLoss: 17350.29\n",
      "Training example 400 / 1031. DiscLoss: 779.66, GenLoss: 17302.79\n",
      "Training example 500 / 1031. DiscLoss: 531.56, GenLoss: 17245.57\n",
      "Training example 600 / 1031. DiscLoss: 190.36, GenLoss: 17241.19\n",
      "Training example 700 / 1031. DiscLoss: -132.72, GenLoss: 17237.47\n",
      "Training example 800 / 1031. DiscLoss: -321.17, GenLoss: 17236.24\n",
      "Training example 900 / 1031. DiscLoss: -431.14, GenLoss: 17220.16\n",
      "Training example 1000 / 1031. DiscLoss: -557.33, GenLoss: 17206.57\n",
      "------- EPOCH 3 --------\n",
      "Training example 0 / 1031. DiscLoss: -5.99, GenLoss: 859.74\n",
      "Training example 100 / 1031. DiscLoss: -705.56, GenLoss: 17193.08\n",
      "Training example 200 / 1031. DiscLoss: -777.35, GenLoss: 17199.01\n",
      "Training example 300 / 1031. DiscLoss: -926.39, GenLoss: 17181.17\n",
      "Training example 400 / 1031. DiscLoss: -916.20, GenLoss: 17183.25\n",
      "Training example 500 / 1031. DiscLoss: -1051.40, GenLoss: 17172.29\n",
      "Training example 600 / 1031. DiscLoss: -1367.08, GenLoss: 17164.69\n",
      "Training example 700 / 1031. DiscLoss: -1979.17, GenLoss: 17155.79\n",
      "Training example 800 / 1031. DiscLoss: -2545.41, GenLoss: 17151.24\n",
      "Training example 900 / 1031. DiscLoss: -3352.77, GenLoss: 17169.82\n",
      "Training example 1000 / 1031. DiscLoss: -4900.93, GenLoss: 17206.96\n",
      "------- EPOCH 4 --------\n",
      "Training example 0 / 1031. DiscLoss: -31.95, GenLoss: 862.12\n",
      "Training example 100 / 1031. DiscLoss: -7635.27, GenLoss: 17283.17\n",
      "Training example 200 / 1031. DiscLoss: -11103.36, GenLoss: 17362.44\n",
      "Training example 300 / 1031. DiscLoss: -17434.17, GenLoss: 17525.90\n",
      "Training example 400 / 1031. DiscLoss: -26007.15, GenLoss: 17740.71\n",
      "Training example 500 / 1031. DiscLoss: -43483.68, GenLoss: 18130.93\n",
      "Training example 600 / 1031. DiscLoss: -3512.95, GenLoss: 17406.57\n",
      "Training example 700 / 1031. DiscLoss: 469.07, GenLoss: 16942.83\n",
      "Training example 800 / 1031. DiscLoss: -282.15, GenLoss: 16934.66\n",
      "Training example 900 / 1031. DiscLoss: -723.00, GenLoss: 16934.36\n",
      "Training example 1000 / 1031. DiscLoss: -1133.98, GenLoss: 16926.43\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Apr 20 14:41:19 2019\n",
    "\n",
    "@author: karm2204\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "References:\n",
    "\"\"\"\n",
    "#%%\n",
    "\n",
    "# https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "# https://discuss.pytorch.org/t/gradient-penalty-with-respect-to-the-network-parameters/11944/2\n",
    "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "\n",
    "#%%\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def get_data_loader(dataset_location, batch_size):\n",
    "    trainvalid = torchvision.datasets.SVHN(\n",
    "        dataset_location, split='train',\n",
    "        download=True,\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    trainset_size = int(len(trainvalid) * 0.9)\n",
    "    trainset, validset = dataset.random_split(\n",
    "        trainvalid,\n",
    "        [trainset_size, len(trainvalid) - trainset_size]\n",
    "    )\n",
    "\n",
    "    train = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    valid = torch.utils.data.DataLoader(\n",
    "        validset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.SVHN(\n",
    "            dataset_location, split='test',\n",
    "            download=True,\n",
    "            transform=image_transform\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "#%%     \n",
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator. Input is noise and latent variables, output is a generated\n",
    "    image.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 512, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(128, 3, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        )\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_):\n",
    "        input_ = input_.view(input_.size(0), -1, 1, 1)\n",
    "        input_ = self.main(input_)\n",
    "        input_ = self.activation(input_)\n",
    "        return input_\n",
    "\n",
    "#%%\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Discriminator. Input is an image (real or generated), output is\n",
    "    P(generated), continuous latent variables, discrete latent variables.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 1, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        input_ = self.main(image)\n",
    "        input_ = input_.view(-1, 1).squeeze(1)\n",
    "        return input_\n",
    "\n",
    "#%%\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.latent_dim = 100\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "        self.lambda_gp = 10.0\n",
    "#%%   \n",
    "def compute_gradient_penalty(x, y, gan):\n",
    "    '''\n",
    "        Random weight term for interpolation between real and fake samples\n",
    "        Get random interpolation between real x and fake y samples\n",
    "    '''\n",
    "    alpha = torch.rand((x.size(0), 1, 1, 1), device = x.device)\n",
    "    lin_interpol = alpha * x + (1-alpha) * y\n",
    "    lin_interpol.requires_grad_(True)\n",
    "    # need a fake grad output\n",
    "    output = gan.discriminator(lin_interpol)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=output,\n",
    "        inputs=lin_interpol,\n",
    "        grad_outputs=torch.ones_like(output),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )\n",
    "    gradients = gradients[0]\n",
    "    gradient = gradients.view(gradients.size(0), -1)\n",
    "    norm_2 = gradient.norm(p=2, dim=1)\n",
    "    gradient_penalty = ((norm_2 - 1).pow(2)).mean()\n",
    "    return gradient_penalty\n",
    "#%% \n",
    "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html \n",
    "\n",
    "def visual_samples(gan, dimensions, device, svhn_loader, step=0):\n",
    "    # Generate new images\n",
    "    z = torch.randn(64, dimensions, device=device)\n",
    "    generated = gan.generator(z)\n",
    "    #debug\n",
    "    torchvision.utils.save_image(generated, 'images/gan/3.1gan-generated.png', normalize=False)\n",
    "    #torchvision.utils.save_image(generated, f\"images/gan/3_1gan-generated-{step}.png\", normalize=False)\n",
    "    \n",
    "def disentangled_representation(gan, dimensions, device, epsilon = 3):\n",
    "    #Sample from prior p(z) which is a Std Normal\n",
    "    z = torch.randn(dimensions, device=device)\n",
    "    \n",
    "    #Copy this tensor times its number of dimensions and make perturbations on each dimension\n",
    "    #The first element is the original sample\n",
    "    z = z.repeat(dimensions+1, 1)\n",
    "    for i, sample in enumerate(z[1:]):\n",
    "        sample[i] += epsilon\n",
    "\n",
    "    generated = gan.generator(z)\n",
    "    torchvision.utils.save_image(generated, 'images/gan/3_2positive_eps.png', normalize=False)\n",
    "\n",
    "    #Do the same with the negative epsilon\n",
    "    epsilon = -2*epsilon\n",
    "    for i, sample in enumerate(z[1:]):\n",
    "        sample[i] += epsilon\n",
    "\n",
    "    #Make a batch of the pertubations and pass it through the generator\n",
    "    generated = gan.generator(z)\n",
    "    torchvision.utils.save_image(generated, 'images/gan/3_2negative_eps.png', normalize=False)\n",
    "    \n",
    "#%%\n",
    "    \n",
    "def interpolation(gan, dimensions, device):\n",
    "    # Interpolate in the latent space between z_0 and z_1\n",
    "    z_0 = torch.randn(1,dimensions, device=device)\n",
    "    z_1 = torch.randn(1,dimensions, device=device)\n",
    "    z_a = torch.zeros([11,dimensions], device=device)\n",
    "\n",
    "    for i in range(11):\n",
    "        a = i/10\n",
    "        z_a[i] = a*z_0 + (1-a)*z_1\n",
    "\n",
    "    generated = gan.generator(z_a)\n",
    "    torchvision.utils.save_image(generated, 'images/gan/3_3latent.png', normalize = False)\n",
    "    \n",
    "    # Interpolate in the data space between x_0 and x_1\n",
    "    x_0 = gan.generator(z_0)\n",
    "    x_1 = gan.generator(z_1)\n",
    "    x_a = torch.zeros(11,x_0.size()[1],x_0.size()[2],x_0.size()[3], device = device)\n",
    "\n",
    "    for i in range(11):\n",
    "        a = i/10\n",
    "        x_a[i] = torch.lerp(x_0, x_1, a)\n",
    "\n",
    "    torchvision.utils.save_image(x_a, 'images/gan/3_3data.png', normalize = False)\n",
    "\n",
    "\n",
    "def save_images(img_dir: str):\n",
    "    import os\n",
    "    gan = GAN()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    gan.load_state_dict(torch.load('GAN_q3_save.pth', map_location = device))\n",
    "    gan = gan.to(device)\n",
    "    gan.eval()\n",
    "    \n",
    "    for p in gan.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        latents = torch.randn(100, 100, device=device)\n",
    "        images = gan.generator(latents)\n",
    "        os.makedirs(f\"{img_dir}/img/\", exist_ok=True)\n",
    "        for j, image in enumerate(images):\n",
    "            filename = f\"{img_dir}/img/{i * 100 + j:03d}.png\"\n",
    "            torchvision.utils.save_image(image, filename, normalize=False)\n",
    "\n",
    "#%%\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Running on {device}\")\n",
    "    \n",
    "    gan = GAN()\n",
    "    gan = gan.to(device)\n",
    "    gan.train()\n",
    "\n",
    "    gen_step = 5\n",
    "\n",
    "    D_optimizer = torch.optim.Adam(gan.discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "    G_optimizer = torch.optim.Adam(gan.generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "    train, valid, test = get_data_loader(\"svhn\", 64)\n",
    "    \n",
    "    try: \n",
    "        gan.load_state_dict(torch.load('GAN_q3_save.pth', map_location=device))\n",
    "        print('----Using saved model----')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        for epoch in range(5):\n",
    "            print(f\"------- EPOCH {epoch} --------\")\n",
    "\n",
    "            running_loss_d = 0\n",
    "            running_loss_g = 0\n",
    "            \n",
    "            for i, (img, _) in enumerate(train):\n",
    "                gan.train()\n",
    "\n",
    "                # Training the discriminator\n",
    "                D_optimizer.zero_grad()                \n",
    "                img = img.to(device)\n",
    "                latents = torch.randn([img.shape[0], gan.latent_dim], device=device)\n",
    "                fakes = gan.generator(latents).detach()\n",
    "                \n",
    "                fakes_score = gan.discriminator(fakes)\n",
    "                fakes_score_mean = fakes_score.mean()\n",
    "                fakes_score_mean.backward()\n",
    "\n",
    "                reals_score = gan.discriminator(img)\n",
    "                reals_score_mean = -reals_score.mean()\n",
    "                reals_score_mean.backward()\n",
    "                loss = fakes_score_mean + reals_score_mean\n",
    "            \n",
    "                grad_penalty = gan.lambda_gp * compute_gradient_penalty(img, fakes, gan)\n",
    "                grad_penalty.backward()\n",
    "                loss += grad_penalty\n",
    "                \n",
    "                D_optimizer.step()\n",
    "                running_loss_d += loss\n",
    "\n",
    "                # training the generator\n",
    "                if i % gen_step == 0:\n",
    "                    G_optimizer.zero_grad()\n",
    "                    latents = torch.randn([img.shape[0], gan.latent_dim], device=device)\n",
    "                    fakes = gan.generator(latents)\n",
    "\n",
    "                    fakes_score = gan.discriminator(fakes)\n",
    "                    fakes_score_mean = -fakes_score.mean()\n",
    "                    fakes_score_mean.backward()\n",
    "\n",
    "                    G_optimizer.step()\n",
    "                    running_loss_g += fakes_score_mean\n",
    "                    \n",
    "                if(i%10 == 0):\n",
    "                    visual_samples(gan, 100, device, test)\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Training example {i} / {len(train)}. DiscLoss: {running_loss_d:.2f}, GenLoss: {running_loss_g:.2f}\")\n",
    "                    running_loss_d = 0\n",
    "                    running_loss_g = 0\n",
    "        \n",
    "        torch.save(gan.state_dict(), 'GAN_q3_save.pth')\n",
    "\n",
    "    dimensions = 100\n",
    "        \n",
    "    gan.eval()\n",
    "    #3_1 Visual samples\n",
    "    visual_samples(gan, dimensions, device, test)\n",
    "\n",
    "    #3_2 Disentangled representation\n",
    "    disentangled_representation(gan, dimensions, device, epsilon=10)\n",
    "\n",
    "    #3_3 Interpolation\n",
    "    interpolation(gan, dimensions, device)\n",
    "\n",
    "    img_dir = \"images/gan/fid\"\n",
    "    save_images(img_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
